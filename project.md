# Take-at-Home Task ‚Äì Backend (Vector DB)

Congrats on making it thus far in the interview process!
Here is a task for you to show us where you shine the most ‚ú®

The purpose is not to see how fast you go or what magic tricks you know in Python ‚Äî it‚Äôs mostly to understand how clearly you think and code. üôÇ

If you think clearly and your code is clean, you‚Äôre already better than 90% of applicants!

> üí° Feel free to use Cursor, but only where it makes sense. Don‚Äôt overuse it ‚Äî it introduces bugs and is super verbose and not really Pythonic.

---

## ‚öôÔ∏è Objective

The goal of this project is to develop a **REST API** that allows users to **index** and **query** their documents within a **Vector Database**.

A Vector Database specializes in storing and indexing vector embeddings, enabling fast retrieval and similarity searches.
This capability is crucial for applications involving NLP, recommendation systems, and more.

The REST API should be **containerized in a Docker container**.

---

## üìò Definitions

To ensure a clear understanding, let‚Äôs define some key concepts:

1. **Chunk**: A piece of text with an associated embedding and metadata.
2. **Document**: A collection of multiple chunks and its own metadata.
3. **Library**: A collection of documents and metadata.

---

## üß© API Requirements

The API should:

1. Allow users to **create, read, update, and delete (CRUD)** libraries.
2. Allow users to CRUD documents and chunks within a library.
3. **Index** the contents of a library.
4. Perform **k-Nearest Neighbor (kNN)** vector searches over a selected library.

---

## üêç Guidelines

The code should be written in **Python**, since that‚Äôs our backend language.

Here‚Äôs a suggested implementation path:

1. **Define the models:** `Chunk`, `Document`, and `Library`.
   - Use a **fixed schema** for simplicity (fewer validation issues).
   - Optionally, let users define their own schemas for extra credit.
   - Use **Pydantic** for data modeling.

2. **Implement two or three indexing algorithms**.
   - Don‚Äôt use external libraries ‚Äî code them yourself.
   - Explain **space and time complexity** for each.
   - Justify your design choice.

3. **Handle data concurrency** ‚Äî ensure no data races between reads and writes.
   - Explain your synchronization design choices.

4. **Implement CRUD logic** for libraries, documents, and chunks.
   - Use a **Service layer** to decouple API endpoints from business logic.

5. **Implement the API layer** on top of your service logic.

6. **Containerize the project** using Docker.

---

## üåü Extra Points (Optional Enhancements)

1. **Metadata Filtering**
   - Add filters for kNN queries, e.g., search all chunks created after a date or containing a specific keyword.

2. **Persistence to Disk**
   - Persist the DB state to disk so the Docker container can restart and resume.
   - Explain trade-offs (performance, consistency, durability).

3. **Leader‚ÄìFollower Architecture**
   - Implement leader-follower (master-slave) architecture for multi-node clusters.
   - Handle leader election, data replication, failover, scalability, and availability.

4. **Python SDK Client**
   - Develop a Python SDK for your API with proper documentation and usage examples.

5. **Durable Execution (Bonus with Temporal.io)**
   - Use **Temporal (Python SDK)** for orchestrating query execution workflows.
   - Set up a **local Temporal cluster** with Docker.
   - Design a workflow (`QueryWorkflow`) handling:
     - User query ‚Üí preprocessing ‚Üí retrieval ‚Üí reranking ‚Üí answer generation.
   - Include:
     - Client connection to Temporal.
     - Worker executing tasks.
     - Demonstrate **sync vs async**, **workflow vs activity**, and bonus **signals/queries**.

---

## üö´ Constraints

- **Do NOT** use external vector DBs (e.g., ChromaDB, Pinecone, FAISS).
- You **can use** `numpy` for trigonometric functions like `cos`, `sin`, etc.
- You **do not** need to build a document processing pipeline (OCR, chunking, etc.).
  - Using manually created chunks is fine.

---

## üß± Tech Stack

- **Backend:** Python + FastAPI + Pydantic
- **Embedding API:** [Cohere Embeddings](https://cohere.com/embeddings)
  - Example API keys for testing:
    ```
    pa6sRhnVAedMVClPAwoCvC1MjHKEwjtcGSTjWRMd
    rQsWxQJOK89Gp87QHo6qnGtPiWerGJOxvdg59o5f
    ```

---

## üßÆ Evaluation Criteria

We‚Äôll evaluate both **functionality** and **code quality**.

### Code Quality
- Static typing
- FastAPI best practices
- Pydantic schema validation
- Code modularity & reusability
- RESTful endpoint design
- Proper Docker containerization
- Testing
- Error handling
- Domain-driven design (DDD) structure:
  - Separate API endpoints from services
  - Separate services from repositories
- Pythonic style:
  - Early returns
  - Use composition over inheritance
  - Avoid hardcoding values (especially HTTP codes ‚Äî use [FastAPI status codes](https://fastapi.tiangolo.com/reference/status/))

### Functionality
- Does everything work as expected?

---

## üì¶ Deliverables

1. **Source Code:**
   - Link to a public GitHub repository with all code.

2. **Documentation:**
   - A `README` explaining:
     - Your approach and design choices
     - How to run the project locally
     - Any additional info

3. **Demo Video:**
   - Show how to install and use the project.
   - Walk through your design and key decisions.

---

## ‚è±Ô∏è Timeline

- Expected duration: **4 days (96 hours)**.
- However, if you need more time to improve quality, feel free to take it! üöÄ

At the end of the day, if it doesn‚Äôt impress the team ‚Äî it won‚Äôt fly. So give it your best shot ‚úàÔ∏è

---

## üí¨ Questions

Feel free to reach out anytime if you encounter issues or have questions about the task.
